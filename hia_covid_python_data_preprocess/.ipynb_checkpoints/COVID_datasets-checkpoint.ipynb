{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge datapackage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c conda-forge jsontableschema-panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datapackage import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas() # to use in progress_apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import us\n",
    "import addfips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get COVID-19 DataPackage and Process Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "package = Package('https://datahub.io/core/covid-19/datapackage.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of all resources:\n",
    "resources = package.descriptor['resources']\n",
    "resourceList = [resources[x]['name'] for x in range(0, len(resources))]\n",
    "#print(resourceList)\n",
    "\n",
    "us_resourceList = [i for i in resourceList if (\"us\" in i and \"csv\" in i and \"preview\" not in i)]\n",
    "\n",
    "\n",
    "print(us_resourceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package.descriptor['resources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_csv = package.get_resource('us_simplified_csv').read(keyed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(us_simplified_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = dict()\n",
    "def make_pandas_dfs_from_resource(resourcenamelist):\n",
    "    for resourcename in resourcenamelist:\n",
    "        try:\n",
    "            resource = package.get_resource(resourcename).read(keyed=True)\n",
    "            df_dict[resourcename] = pd.DataFrame(resource)\n",
    "            print(\"{name} is complete\".format(name=resourcename))\n",
    "        except:\n",
    "            print(\"There was an error for {name}\".format(name=resourcename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_pandas_dfs_from_resource(us_resourceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df = df_dict['us_simplified_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_deaths_df = df_dict['us_deaths_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_confirmed_df = df_dict['us_confirmed_csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_dict.values():\n",
    "    print(i.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape File with Current Totals of Cases and Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Province/State'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df.rename(columns={'Province/State': 'State'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df = us_simplified_df[us_simplified_df.Admin2 != 'Unassigned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df.Date = us_simplified_df.Date.astype(\"datetime64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Deaths_Previous'] = us_simplified_df.groupby(['Admin2','State'])['Deaths'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Confirmed_Previous'] = us_simplified_df.groupby(['Admin2','State'])['Confirmed'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Deaths_New'] = us_simplified_df.Deaths - us_simplified_df.Deaths_Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Deaths_New_+7'] = us_simplified_df.groupby(['Admin2','State'])['Deaths_New'].shift(-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Deaths_New_+14'] = us_simplified_df.groupby(['Admin2','State'])['Deaths_New'].shift(-14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Deaths_New_+21'] = us_simplified_df.groupby(['Admin2','State'])['Deaths_New'].shift(-21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Deaths_New_+28'] = us_simplified_df.groupby(['Admin2','State'])['Deaths_New'].shift(-28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df['Confirmed_New'] =  us_simplified_df.Confirmed - us_simplified_df.Confirmed_Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add locationcol key \n",
    "us_simplified_df['locationcol'] = us_simplified_df['Admin2']+'|'+us_simplified_df['State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrplot for all of the variables\n",
    "sns.set(rc={'figure.figsize':(11,8)})\n",
    "corr = us_simplified_df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_all_locations = list(us_simplified_df['locationcol'].unique())\n",
    "\n",
    "# Sample half of the locations\n",
    "# sample_num = int(round(len(list_all_locations)/2, 0))\n",
    "# list_locations_sampled = list_all_locations  #sample(list_all_locations, sample_num) list_all_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix Counties - Cities Confusion\n",
    "\n",
    "Some counties and cities have the same name. In the COVID dataset, the cities are reported with \"city\" but the counties have no appelation. In order for the lookup to work properly, we need to add \"County\" to these county-level reports. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df_nona = us_simplified_df.dropna()\n",
    "\n",
    "fairfax = us_simplified_df_nona[us_simplified_df_nona.Admin2.str.contains(\"City\")]\n",
    "\n",
    "fairfax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairfax.groupby(\"Admin2\").max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairfax.locationcol = fairfax.Admin2+'|'+fairfax.State\n",
    "\n",
    "cities_list = list(fairfax.locationcol.unique())\n",
    "\n",
    "counties_with_citynames_list = [i.replace(' City','') for i in cities_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_with_citynames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_county_issues = us_simplified_df[(us_simplified_df.Admin2+'|'+us_simplified_df.State).isin(counties_with_citynames_list) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_issues = us_simplified_df[(us_simplified_df.Admin2+'|'+us_simplified_df.State).isin(counties_with_citynames_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_issues.Admin2 = county_issues.Admin2+' County'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_issues.Admin2.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df_countyfixed = pd.concat([county_issues,no_county_issues],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df_countyfixed.locationcol = us_simplified_df_countyfixed.Admin2+'|'+us_simplified_df_countyfixed.State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df_countyfixed.shape[0]/us_simplified_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df = us_simplified_df_countyfixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County Level - Add the Rolling Averages and Recombine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_frames = []\n",
    "for i in tqdm(list_all_locations):\n",
    "    frame = us_simplified_df[us_simplified_df.locationcol == i]\n",
    "    frame['Confirmed_New_RollingAvg'] = frame.rolling(7, min_periods=7, center=False, on=\"Date\")['Confirmed_New'].mean()\n",
    "    frame['Deaths_New_RollingAvg'] = frame.rolling(7, min_periods=7, center=False, on=\"Date\")['Deaths_New'].mean()\n",
    "    frame['Deaths_New_+7_RollingAvg'] = frame.rolling(7, min_periods=7, center=False, on=\"Date\")['Deaths_New_+7'].mean()\n",
    "    frame['Deaths_New_+14_RollingAvg'] = frame.rolling(7, min_periods=7, center=False, on=\"Date\")['Deaths_New_+14'].mean()\n",
    "    frame['Deaths_New_+21_RollingAvg'] = frame.rolling(7, min_periods=7, center=False, on=\"Date\")['Deaths_New_+21'].mean()\n",
    "    frame['Deaths_New_+28_RollingAvg'] = frame.rolling(7, min_periods=7, center=False, on=\"Date\")['Deaths_New_+28'].mean()\n",
    "    list_frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df = pd.concat(list_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at one county\n",
    "yuma = large_frame_df[large_frame_df['locationcol'] == 'Yuma|Arizona']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = sns.lineplot(x=\"Date\", y=\"Deaths_New\", data=yuma)\n",
    "plt1 = sns.lineplot(x=\"Date\", y=\"Deaths_New_+7_RollingAvg\", data=yuma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Corrplot\n",
    "sns.set(rc={'figure.figsize':(9,11)})\n",
    "corr = large_frame_df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping FIPS Codes to the COVID Dataset using addfips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df.columns\n",
    "# No FIPS codes natively included in this dataset, so I had to construct a mapping process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_location(locationstring):\n",
    "    af = addfips.AddFIPS()\n",
    "    try:\n",
    "        namelist = locationstring.split('|')\n",
    "        statename = namelist[1]\n",
    "        countyname = namelist[0]\n",
    "        fipscode = af.get_county_fips(countyname, state=statename)\n",
    "        return fipscode\n",
    "    except:\n",
    "        return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counties = pd.DataFrame(large_frame_df.locationcol.unique(), columns = ['locationcol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counties['County_FIPS'] = unique_counties['locationcol'].progress_apply(lookup_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing County-Level Data for COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df = large_frame_df.merge(unique_counties, on=\"locationcol\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df_mapping_counties = large_frame_df.groupby(['County_FIPS','State'])['Deaths'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df_mapping_counties.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roll Up to State Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_simplified_df = us_simplified_df.groupby(['State','Date']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_frames = []\n",
    "for i in tqdm(list(us_simplified_df.State.unique())):\n",
    "    frame = us_simplified_df[us_simplified_df.State == i]\n",
    "    frame['Confirmed_New_RollingAvg'] = frame.rolling(7, min_periods=7, center=True, on=\"Date\")['Confirmed_New'].mean()\n",
    "    frame['Deaths_New_+7_RollingAvg'] = frame.rolling(7, min_periods=7, center=True, on=\"Date\")['Deaths_New_+7'].mean()\n",
    "    frame['Deaths_New_+14_RollingAvg'] = frame.rolling(7, min_periods=7, center=True, on=\"Date\")['Deaths_New_+14'].mean()\n",
    "    frame['Deaths_New_+21_RollingAvg'] = frame.rolling(7, min_periods=7, center=True, on=\"Date\")['Deaths_New_+21'].mean()\n",
    "    frame['Deaths_New_+28_RollingAvg'] = frame.rolling(7, min_periods=7, center=True, on=\"Date\")['Deaths_New_+28'].mean()\n",
    "    list_frames.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statelevel_large_df = pd.concat(list_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get State Region Names from State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name_from_state(x):\n",
    "    state = us.states.lookup(x)\n",
    "    normalized_state_name = state.name\n",
    "    return normalized_state_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_regions = pd.read_csv('https://raw.githubusercontent.com/cphalpert/census-regions/master/us%20census%20bureau%20regions%20and%20divisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#states_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_regions_merged = statelevel_large_df.merge(states_regions, on=\"State\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of these don't have regions\n",
    "states_regions_merged[states_regions_merged.Region.isna() == True]['State'].unique()\n",
    "states_regions_merged.Region.fillna('Other Region',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_regions_merged.Confirmed_New_RollingAvg.isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_regions_merged_nona = states_regions_merged.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=\"Deaths_New_+21_RollingAvg\",x=\"Confirmed_New_RollingAvg\", hue=\"Region\", data=states_regions_merged_nona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(y=\"Deaths_New_+7_RollingAvg\",x=\"Confirmed_New_RollingAvg\", hue=\"Region\", data=states_regions_merged_nona)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory OLS Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def regress_two_var(df, X, Y, datecutoff = \"2020-01-01\"):\n",
    "    # Cleaning up the dataframe\n",
    "    df = df[df.Date >= datecutoff]\n",
    "    df = df[df.Date <= \"2020-10-01\"]\n",
    "    df = df[df['{Y}'.format(Y=Y)].isna() == False]\n",
    "    df = df[df['{X}'.format(X=X)].isna() == False]\n",
    "    #dataframe[\"ratio\"] = dataframe['{Y}'.format(Y=Y)]/dataframe['{X}'.format(X=X)]\n",
    "    Xvar =  df['{X}'.format(X=X)].values.reshape(-1, 1) \n",
    "    Xvar1 = sm.add_constant(Xvar) # need to do this for statsmodels for some reason\n",
    "    Yvar = df['{Y}'.format(Y=Y)].values.reshape(-1, 1) \n",
    "    mod = sm.OLS(endog=Yvar,exog=Xvar1)\n",
    "    res = mod.fit()\n",
    "    print(res.summary())\n",
    "    # Graph the regression\n",
    "    linear_regressor = LinearRegression()  # create object for the class\n",
    "    fitted_model = linear_regressor.fit(X=Xvar,y=Yvar)  # perform linear regression\n",
    "    Y_pred = fitted_model.predict(Xvar)  # make predictions\n",
    "    #return fitted_model\n",
    "    plt.scatter(y=Yvar, x=Xvar)\n",
    "    plt.plot(Xvar, Y_pred, color='red')\n",
    "    plt.title(\"{X} on {Y} Regression\".format(X=X,Y=Y))\n",
    "    plt.show()\n",
    "    #Scatterplot to show data\n",
    "    sns.scatterplot(y='{Y}'.format(Y=Y),x='{X}'.format(X=X), data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regress_two_var(states_regions_merged_nona,\"Confirmed_New_RollingAvg\",\"Deaths_New_+28_RollingAvg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## County-Level Frame with Divisions Added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df_divisions = large_frame_df.merge(states_regions, on=\"State\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_frame_df_divisions.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Full Dataset to File and Save Sample to FIle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'/Users/philip.ballentine/Documents/hia_covid_repo/hia_covid_data_assets/')\n",
    "path = str(os.getcwd())\n",
    "filename = \"covid_dataset_full.csv\"\n",
    "large_frame_df_divisions.to_csv(filename)\n",
    "print(\"{filename} has been created in {path}\".format(filename=filename, path=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sample\n",
    "large_frame_df_divisions_sample = large_frame_df_divisions.sample(frac=.1)\n",
    "\n",
    "filename = \"covid_dataset_sample.csv\"\n",
    "large_frame_df_divisions_sample.to_csv(filename)\n",
    "print(\"{filename} has been created in {path}\".format(filename=filename, path=path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
